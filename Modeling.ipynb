{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26d1edf",
   "metadata": {},
   "source": [
    "# Load Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b84b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System, Data, Time, and Spec Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np \n",
    "from line_profiler import LineProfiler  # Code peformance\n",
    "profiler = LineProfiler()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "import multiprocess as mp\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "#from pandas.io.json import json_normalize  # Older version\n",
    "from pandas import json_normalize  # Newer version\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "\n",
    "# Natural Language Processing Libraries\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "import string\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas import json_normalize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "punctuation = set(punctuation)\n",
    "punctuation.update({'_', '-','â€˜'})\n",
    "english_words = set(words.words())\n",
    "from fuzzywuzzy import process\n",
    "#nltk.download('words')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# SQL Interface Libraries\n",
    "import pymysql as mysql\n",
    "import mysql.connector\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import event\n",
    "from string import punctuation\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import yeojohnson\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay,roc_auc_score, roc_curve \n",
    "from sklearn.metrics import classification_report, mean_squared_error, f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from dmba import classificationSummary, AIC_score, BIC_score, plotDecisionTree,gainsChart\n",
    "from scikitplot.metrics import plot_lift_curve, plot_cumulative_gain\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.metrics import specificity_score, sensitivity_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import KFold\n",
    "from dmba import stepwise_selection, classificationSummary, backward_elimination\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Importing Custom Functions\n",
    "import nbimporter\n",
    "from Functions import nan_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45efe7",
   "metadata": {},
   "source": [
    "# Test Join Outside of Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b30919",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.8 GiB for an array with shape (1001, 2653735) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m merged_df1_df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df1, df2, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Merge the result with df3\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m final_merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df1_df2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Display the final merged DataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_merged_df)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:879\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    877\u001b[0m left\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m llabels\n\u001b[0;32m    878\u001b[0m right\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m rlabels\n\u001b[1;32m--> 879\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_reindex_columns_na_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    221\u001b[0m             axes[i],\n\u001b[0;32m    222\u001b[0m             indexers[i],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[1;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 19.8 GiB for an array with shape (1001, 2653735) and data type int64"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('DataLibrary/events_table2023.csv')\n",
    "df2 = pd.read_csv('DataLibrary/patient_drugs_table2023.csv')\n",
    "df3 = pd.read_csv('DataLibrary/reactions_table2023.csv')\n",
    "\n",
    "# Merge df1 and df2\n",
    "merged_df1_df2 = pd.merge(df1, df2, on='event_id', how='inner')\n",
    "\n",
    "# Merge the result with df3\n",
    "final_merged_df = pd.merge(merged_df1_df2, df3, on='event_id', how='inner')\n",
    "\n",
    "# Display the final merged DataFrame\n",
    "print(final_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3876082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>year</th>\n",
       "      <th>expedited</th>\n",
       "      <th>report_source</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>company_name</th>\n",
       "      <th>patient_drug_id</th>\n",
       "      <th>spl_set_id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>med_product</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>manufacturers</th>\n",
       "      <th>manu_num</th>\n",
       "      <th>rxcui</th>\n",
       "      <th>unii</th>\n",
       "      <th>ndc9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>jp</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>['nbi']</td>\n",
       "      <td>1</td>\n",
       "      <td>ba74e3cd-b06f-4145-b284-5fd6b84ff3c9</td>\n",
       "      <td>['dabigatran', 'etexilate', 'mesylate', 'dabig...</td>\n",
       "      <td>['dabigatran', 'etexilate', 'mesylate', 'dabig...</td>\n",
       "      <td>['dabigatran', 'etexilate', 'mesylate', 'dabig...</td>\n",
       "      <td>['boehringer-ingelheim-pharmaceuticals-']</td>\n",
       "      <td>1</td>\n",
       "      <td>1037045.0</td>\n",
       "      <td>['SC7NUW5IIT']</td>\n",
       "      <td>5970108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ca</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['roche']</td>\n",
       "      <td>9</td>\n",
       "      <td>2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['actemra']</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['genentech']</td>\n",
       "      <td>1</td>\n",
       "      <td>1441527.0</td>\n",
       "      <td>['I031V2H011']</td>\n",
       "      <td>50242135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ca</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['roche']</td>\n",
       "      <td>10</td>\n",
       "      <td>2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['actemra']</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['genentech']</td>\n",
       "      <td>1</td>\n",
       "      <td>1441527.0</td>\n",
       "      <td>['I031V2H011']</td>\n",
       "      <td>50242135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ca</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['roche']</td>\n",
       "      <td>11</td>\n",
       "      <td>2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['actemra']</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['genentech']</td>\n",
       "      <td>1</td>\n",
       "      <td>1441527.0</td>\n",
       "      <td>['I031V2H011']</td>\n",
       "      <td>50242135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ca</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['roche']</td>\n",
       "      <td>12</td>\n",
       "      <td>2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['actemra']</td>\n",
       "      <td>['tocilizumab']</td>\n",
       "      <td>['genentech']</td>\n",
       "      <td>1</td>\n",
       "      <td>1441527.0</td>\n",
       "      <td>['I031V2H011']</td>\n",
       "      <td>50242135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  year  expedited  report_source country   age  sex  weight  \\\n",
       "0         1  2024          1              1      jp  84.0    2    50.0   \n",
       "1         2  2024          1              3      ca  71.0    2    77.0   \n",
       "2         2  2024          1              3      ca  71.0    2    77.0   \n",
       "3         2  2024          1              3      ca  71.0    2    77.0   \n",
       "4         2  2024          1              3      ca  71.0    2    77.0   \n",
       "\n",
       "   serious_outcome company_name  patient_drug_id  \\\n",
       "0                2      ['nbi']                1   \n",
       "1                1    ['roche']                9   \n",
       "2                1    ['roche']               10   \n",
       "3                1    ['roche']               11   \n",
       "4                1    ['roche']               12   \n",
       "\n",
       "                             spl_set_id  \\\n",
       "0  ba74e3cd-b06f-4145-b284-5fd6b84ff3c9   \n",
       "1  2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13   \n",
       "2  2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13   \n",
       "3  2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13   \n",
       "4  2e5365ff-cb2a-4b16-b2c7-e35c6bf2de13   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ['dabigatran', 'etexilate', 'mesylate', 'dabig...   \n",
       "1                                    ['tocilizumab']   \n",
       "2                                    ['tocilizumab']   \n",
       "3                                    ['tocilizumab']   \n",
       "4                                    ['tocilizumab']   \n",
       "\n",
       "                                         med_product  \\\n",
       "0  ['dabigatran', 'etexilate', 'mesylate', 'dabig...   \n",
       "1                                        ['actemra']   \n",
       "2                                        ['actemra']   \n",
       "3                                        ['actemra']   \n",
       "4                                        ['actemra']   \n",
       "\n",
       "                                        generic_name  \\\n",
       "0  ['dabigatran', 'etexilate', 'mesylate', 'dabig...   \n",
       "1                                    ['tocilizumab']   \n",
       "2                                    ['tocilizumab']   \n",
       "3                                    ['tocilizumab']   \n",
       "4                                    ['tocilizumab']   \n",
       "\n",
       "                               manufacturers  manu_num      rxcui  \\\n",
       "0  ['boehringer-ingelheim-pharmaceuticals-']         1  1037045.0   \n",
       "1                              ['genentech']         1  1441527.0   \n",
       "2                              ['genentech']         1  1441527.0   \n",
       "3                              ['genentech']         1  1441527.0   \n",
       "4                              ['genentech']         1  1441527.0   \n",
       "\n",
       "             unii        ndc9  \n",
       "0  ['SC7NUW5IIT']   5970108.0  \n",
       "1  ['I031V2H011']  50242135.0  \n",
       "2  ['I031V2H011']  50242135.0  \n",
       "3  ['I031V2H011']  50242135.0  \n",
       "4  ['I031V2H011']  50242135.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f16362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133423, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b14aff2b-fd02-4373-8f0c-b886ab7e9395",
   "metadata": {},
   "source": [
    "### SQL Password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95daa5f5-c8e9-450b-a74f-b9ade632cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSWORD  = 'LunarLanding$' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1ab8a-ee41-484e-ab5f-b37f23b7080f",
   "metadata": {},
   "source": [
    "## Investigate number of records in each database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b7a789-1b65-4887-8bb7-23dcbdfd0a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0     18481"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql_query = \"\"\"SELECT COUNT(*) FROM patient_reactions\"\"\"\n",
    "\n",
    "\n",
    "cursor.execute(sql_query)\n",
    "result = cursor.fetchall()\n",
    "column_names = [i[0] for i in cursor.description]\n",
    "\n",
    "\n",
    "result_query_df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "result_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f85a2",
   "metadata": {},
   "source": [
    "# Get Dataset from SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd9e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL server\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c46ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Master Query from Data - goal\n",
    "\n",
    "# master_query = \"\"\"SELECT \n",
    "#                 a.serious_outcome,\n",
    "#                 a.expedited,\n",
    "#                 a.age,\n",
    "#                 a.sex,\n",
    "#                 a.year\n",
    "#                 a.weight\n",
    "#                 r.outcome,\n",
    "#                 p.unit_price,\n",
    "#                 p.generic_brand,\n",
    "#                 l.ingredients,\n",
    "#                 l.rxcui,\n",
    "#                 l.set_id,\n",
    "#                 d.manu_num,\n",
    "#                 d.unii\n",
    "#             FROM adverse_events a \n",
    "#                 INNER JOIN patients_reactions r ON a.event_id = r.event_id \n",
    "#                 INNER JOIN patients_drugs d ON r.event_id = d.event_id \n",
    "#                 INNER JOIN prices p ON d.ndc11 = p.ndc11\n",
    "#                 INNER JOIN lables l ON p.ndc11 = l.ndc11\n",
    "#             ORDER BY a.event_id DESC\"\"\"  # Still need to test and figure out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d32654-430f-42a6-ab82-fc1f4de696ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cabozantinib</td>\n",
       "      <td>2999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>83</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cabozantinib</td>\n",
       "      <td>2999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>83</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cabozantinib</td>\n",
       "      <td>2999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>83</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cabozantinib</td>\n",
       "      <td>2999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>83</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cabozantinib</td>\n",
       "      <td>2999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>83</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>2998</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>2998</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>placebo</td>\n",
       "      <td>2998</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>placebo</td>\n",
       "      <td>2998</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cosentyx</td>\n",
       "      <td>2994</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>80</td>\n",
       "      <td>NotRecovered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    med_product  event_id  serious_outcome  expedited  age  sex  year  weight  \\\n",
       "0  cabozantinib      2999                2          1   60    1  2022      83   \n",
       "1  cabozantinib      2999                2          1   60    1  2022      83   \n",
       "2  cabozantinib      2999                2          1   60    1  2022      83   \n",
       "3  cabozantinib      2999                2          1   60    1  2022      83   \n",
       "4  cabozantinib      2999                2          1   60    1  2022      83   \n",
       "5    lenvatinib      2998                2          2   60    1  2022      72   \n",
       "6    lenvatinib      2998                2          2   60    1  2022      72   \n",
       "7       placebo      2998                2          2   60    1  2022      72   \n",
       "8       placebo      2998                2          2   60    1  2022      72   \n",
       "9      cosentyx      2994                2          1   52    2  2022      80   \n",
       "\n",
       "        outcome  \n",
       "0     Recovered  \n",
       "1     Recovered  \n",
       "2     Recovered  \n",
       "3     Recovered  \n",
       "4     Recovered  \n",
       "5         Fatal  \n",
       "6         Fatal  \n",
       "7         Fatal  \n",
       "8         Fatal  \n",
       "9  NotRecovered  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql_query = \"\"\"SELECT \n",
    "d.med_product,\n",
    "d.event_id,\n",
    "d.manu_num,\n",
    "a.serious_outcome,\n",
    "a.expedited,\n",
    "a.age,\n",
    "a.sex,\n",
    "a.year,\n",
    "a.weight,\n",
    "r.outcome\n",
    "FROM adverse_events a \n",
    "\n",
    "INNER JOIN patient_reactions r ON a.event_id = r.event_id\n",
    "INNER JOIN patient_drugs d ON a.event_id = d.event_id\n",
    "\n",
    "ORDER BY a.event_id DESC\n",
    "\"\"\"\n",
    "cursor.execute(sql_query)\n",
    "result = cursor.fetchall()\n",
    "column_names = [i[0] for i in cursor.description]\n",
    "result_query_df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "result_query_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53568a97-fd7e-431a-a13e-ca728b5c5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df.to_csv('DataLibrary/result_query_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df.to_csv('C://Users/halee/Downloads/result_query_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c6afd0-9a64-4f21-90dd-1b3c9e963937",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df = pd.read_csv('DataLibrary/result_query_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b89d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d9885f3c-c9e9-44f6-b292-d7c5a64b0b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  med_product  event_id serious_outcome  expedited   age  sex  year  weight  \\\n",
       "0  lenvatinib       100               2          2  None    1  2022      45   \n",
       "1  lenvatinib       100               2          2  None    1  2022      45   \n",
       "2  lenvatinib       100               2          2  None    1  2022      45   \n",
       "3  filgrastim        99               1          1  None    2  2022      76   \n",
       "4  filgrastim        99               1          1  None    2  2022      76   \n",
       "\n",
       "     outcome  \n",
       "0      Fatal  \n",
       "1      Fatal  \n",
       "2      Fatal  \n",
       "3  Recovered  \n",
       "4  Recovered  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result_query_df['serious_outcome'] = result_query_df['serious_outcome'].astype('category')\n",
    "\n",
    "result_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff3bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d0a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18d54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9fc933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_query_df = result_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb749f",
   "metadata": {},
   "source": [
    "# Preparation for Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bff08906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  med_product  event_id serious_outcome  expedited   age  sex  year  weight  \\\n",
       "0  lenvatinib       100               2          2  None    1  2022      45   \n",
       "1  lenvatinib       100               2          2  None    1  2022      45   \n",
       "2  lenvatinib       100               2          2  None    1  2022      45   \n",
       "3  filgrastim        99               1          1  None    2  2022      76   \n",
       "4  filgrastim        99               1          1  None    2  2022      76   \n",
       "\n",
       "     outcome  \n",
       "0      Fatal  \n",
       "1      Fatal  \n",
       "2      Fatal  \n",
       "3  Recovered  \n",
       "4  Recovered  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d92ebb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med_product</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serious_outcome</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expedited</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>outcome</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column_name  null_count  null_proportion\n",
       "0      med_product           0              0.0\n",
       "1         event_id           0              0.0\n",
       "2  serious_outcome           0              0.0\n",
       "3        expedited           0              0.0\n",
       "4              age          20            100.0\n",
       "5              sex           0              0.0\n",
       "6             year           0              0.0\n",
       "7           weight           0              0.0\n",
       "8          outcome           0              0.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_info(master_query_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1a292",
   "metadata": {},
   "source": [
    "### Update Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b15b7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   med_product      20 non-null     object  \n",
      " 1   event_id         20 non-null     int64   \n",
      " 2   serious_outcome  20 non-null     category\n",
      " 3   expedited        20 non-null     int64   \n",
      " 4   age              0 non-null      object  \n",
      " 5   sex              20 non-null     int64   \n",
      " 6   year             20 non-null     int64   \n",
      " 7   weight           20 non-null     int64   \n",
      " 8   outcome          20 non-null     object  \n",
      "dtypes: category(1), int64(5), object(3)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "master_query_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba278f65",
   "metadata": {},
   "source": [
    "### Define numerical, text, and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "12d2e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can do without med_product for now to keep simple, will finish after module 5 submission\n",
    "cats = ['med_product', 'sex', 'expedited']\n",
    "nums = ['weight', 'age', 'manu_num'] \n",
    "#texts = ['']  # Do reaction and med product as text vector instead of binary matrix? only test out if time permits\n",
    "#all_vars = cats+nums+texts\n",
    "all_vars = cats+nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2aa3854-cdd8-4ed9-a7e2-a9367d7d0adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenvatinib</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>45</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>filgrastim</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>76</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  med_product  event_id serious_outcome  expedited   age  sex  year  weight  \\\n",
       "0  lenvatinib       100               2          2  None    1  2022      45   \n",
       "1  lenvatinib       100               2          2  None    1  2022      45   \n",
       "2  lenvatinib       100               2          2  None    1  2022      45   \n",
       "3  filgrastim        99               1          1  None    2  2022      76   \n",
       "4  filgrastim        99               1          1  None    2  2022      76   \n",
       "\n",
       "     outcome  \n",
       "0      Fatal  \n",
       "1      Fatal  \n",
       "2      Fatal  \n",
       "3  Recovered  \n",
       "4  Recovered  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8e604641-49f8-4658-b0d8-ce35f4e9f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['med_product', 'event_id', 'serious_outcome', 'expedited', 'age', 'sex',\n",
       "       'year', 'weight', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "095d71fb-09d8-4137-9090-c2dc3d798921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['med_product', 'sex', 'expedited', 'weight', 'year']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd9a25",
   "metadata": {},
   "source": [
    "### Create Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "96e0fd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(transformers=[('cat',\n",
       "                                  Pipeline(steps=[('encoder',\n",
       "                                                   OneHotEncoder(drop='if_binary'))]),\n",
       "                                  ['med_product', 'sex', 'expedited']),\n",
       "                                 ('num',\n",
       "                                  Pipeline(steps=[('skew_standardize',\n",
       "                                                   PowerTransformer())]),\n",
       "                                  ['weight', 'year'])],\n",
       "                   verbose_feature_names_out=False)}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a categorical processing pipeline that uses one-hot encoding\n",
    "# Dropping binary columns and drop first of each level** NEED TO ADD**\n",
    "cat_pipe = Pipeline([('encoder', OneHotEncoder(drop='if_binary'))])\n",
    "\n",
    "# Create a numerical processing pipeline that uses skewness correction/center/scale.\n",
    "num_pipe = Pipeline([('skew_standardize', PowerTransformer())])\n",
    "\n",
    "# Create a text token processing step to vectorize tokens\n",
    "#text_pipe = Pipeline([('vector', tf_idf function())])\n",
    "\n",
    "# Combine pipeline steps\n",
    "all_pipe = make_pipeline(\n",
    "    ColumnTransformer([\n",
    "        ('cat', cat_pipe, cats),  # Apply categorical pipeline to categorical columns\n",
    "        ('num', num_pipe, nums),  # Apply numerical pipeline to numerical columns\n",
    "     #   ('text', text_pipe, texts)  # Apply text pipeline to text columns\n",
    "    ],\n",
    "    verbose_feature_names_out=False)  # Set this to False to avoid verbose feature names\n",
    ")\n",
    "# Verify steps\n",
    "all_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b208e",
   "metadata": {},
   "source": [
    "# Split Data into Training/Validation/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "23f9eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and the target variable (y).\n",
    "X = master_query_df[all_vars]\n",
    "\n",
    "#Define outcome variable\n",
    "y = master_query_df[['serious_outcome']]  # Need to Decide 5 Level or 3 Level\n",
    "\n",
    "#Split data\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X_pipe, y, train_size=0.8, random_state = 2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b64b6b65-0802-43cd-ae63-caf0aedaa12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product_filgrastim</th>\n",
       "      <th>med_product_iressa</th>\n",
       "      <th>med_product_lenvatinib</th>\n",
       "      <th>med_product_xolair</th>\n",
       "      <th>med_product_xyrem</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>expedited_2</th>\n",
       "      <th>weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396589</td>\n",
       "      <td>2.106246e+65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>2.106246e+65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    med_product_filgrastim  med_product_iressa  med_product_lenvatinib  \\\n",
       "4                      1.0                 0.0                     0.0   \n",
       "12                     0.0                 0.0                     0.0   \n",
       "\n",
       "    med_product_xolair  med_product_xyrem  sex_2  expedited_2    weight  \\\n",
       "4                  0.0                0.0    1.0          0.0  0.396589   \n",
       "12                 0.0                1.0    1.0          0.0  0.999742   \n",
       "\n",
       "            year  \n",
       "4   2.106246e+65  \n",
       "12  2.106246e+65  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46fad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e15bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "032c0f4a",
   "metadata": {},
   "source": [
    "## Apply Pipeline to Splits Separately to Prevent Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply pipeline to all of X\n",
    "X_train_fit = all_pipe.fit(X_train)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_train_cols = X_train_fit.get_feature_names_out().tolist()\n",
    "X_train_pipe = pd.DataFrame(all_pipe.fit_transform(X_train), columns = X_train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply pipeline to all of X\n",
    "X_test_fit = all_pipe.fit(X_test)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_test_cols = X_test_fit.get_feature_names_out().tolist()\n",
    "X_test_pipe = pd.DataFrame(all_pipe.fit_transform(X_test), columns = X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954529f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply pipeline to all of X\n",
    "X_val_fit = all_pipe.fit(X_val)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_val_cols = X_val_fit.get_feature_names_out().tolist()\n",
    "X_val_pipe = pd.DataFrame(all_pipe.fit_transform(X_val), columns = X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb650195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e207ea03",
   "metadata": {},
   "source": [
    "## Undersample Training Data to Balance Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0a5fdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomUnderSampler instance with a specified random seed and sampling strategy\n",
    "rus = RandomUnderSampler(random_state = 1, sampling_strategy='majority')\n",
    "\n",
    "# Perform random under-sampling on the training dataset\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_pipe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ba158",
   "metadata": {},
   "source": [
    "# Multiclass Classification Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed355f",
   "metadata": {},
   "source": [
    "## White Box Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec591d-8f63-4b01-8e85-9cec598ee4a0",
   "metadata": {},
   "source": [
    "### Logistic Regression L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7646a70b-9aca-40a1-8b0a-f23cabc53c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "med_product_filgrastim    float64\n",
       "med_product_iressa        float64\n",
       "med_product_lenvatinib    float64\n",
       "med_product_xolair        float64\n",
       "med_product_xyrem         float64\n",
       "sex_2                     float64\n",
       "expedited_2               float64\n",
       "weight                    float64\n",
       "year                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5213ceeb-15d8-4c8f-8436-ad51feb0c294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00020037] [0.99979965]\n"
     ]
    }
   ],
   "source": [
    "log_l1 = LogisticRegression(solver='saga', penalty='l1', random_state=1)\n",
    "log_l1.fit(X_train_under, y_train)\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l1.intercept_ , np.exp(log_l1.intercept_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec3450-150c-4d8a-95a4-90553e38c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca165463-02fb-4ea6-a213-2cca1db37508",
   "metadata": {},
   "source": [
    "### Logistic Regression L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5878cf4e-6867-4944-bfab-fdcca9725168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12139508] [0.88568397]\n"
     ]
    }
   ],
   "source": [
    "log_l2 = LogisticRegression(solver='saga', penalty='l2', random_state=1)\n",
    "log_l2.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l2.intercept_ , np.exp(log_l2.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1a1d5",
   "metadata": {},
   "source": [
    "### Logistic Regression L1 w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "207a804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03186184] [1.03237486]\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression model with L1 regularization\n",
    "log_l1_cv = LogisticRegressionCV(solver = 'saga', penalty = 'l1', cv = 2, random_state = 1)\n",
    "# Fit the model to the training data\n",
    "log_l1_cv.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l1_cv.intercept_ , np.exp(log_l1_cv.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63857388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "becf7b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>LogOdds</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weight</td>\n",
       "      <td>-1.492369</td>\n",
       "      <td>0.224839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med_product_filgrastim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_product_iressa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>med_product_lenvatinib</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>med_product_xolair</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>med_product_xyrem</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expedited_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature   LogOdds      Odds\n",
       "7                  weight -1.492369  0.224839\n",
       "0  med_product_filgrastim  0.000000  1.000000\n",
       "1      med_product_iressa  0.000000  1.000000\n",
       "2  med_product_lenvatinib  0.000000  1.000000\n",
       "3      med_product_xolair  0.000000  1.000000\n",
       "4       med_product_xyrem  0.000000  1.000000\n",
       "5                   sex_2  0.000000  1.000000\n",
       "6             expedited_2  0.000000  1.000000\n",
       "8                    year  0.000000  1.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table of coefficient odds\n",
    "d = {'Feature': pd.Series(X_train_under.columns), 'LogOdds': pd.Series(log_l1_cv.coef_[0])}\n",
    "df = pd.DataFrame(data=d).reindex(d['LogOdds'].abs().sort_values(ascending=False).index)\n",
    "df['Odds'] = np.exp(df['LogOdds'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ed9e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ecbaa-f992-4535-a36f-0153dfe8a5a2",
   "metadata": {},
   "source": [
    "### Logistic Regression Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7ad0abb-4c8f-4d9c-8ba4-b590dbb94fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'l1_ratio': 0.0}\n",
      "Best cross-validation score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'l1_ratio': [i / 9 for i in range(10)],  # 10 values from 0 to 1 (0, 0.1, 0.2, ..., 1.0)\n",
    "    'C': [0.01, 0.1, 1, 10, 100]  # Different strengths of regularization\n",
    "}\n",
    "\n",
    "log_reg_elasticnet = LogisticRegression(\n",
    "    penalty='elasticnet',  # Use Elastic Net regularization\n",
    "    solver='saga',        # Solver that supports Elastic Net\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg_elasticnet,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',   # Or another metric of choice\n",
    "    cv=5,                 # Number of cross-validation folds\n",
    "    n_jobs=-1              # Use all available CPUs\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best cross-validation score: {best_score:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e3159",
   "metadata": {},
   "source": [
    "### Single Decision Tree with Grid Search and 10k-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adfed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search for in tree\n",
    "param_grid = {\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'min_samples_leaf' : [1,2,3,4,5]\n",
    "    \n",
    "}\n",
    "# Create a GridSearchCV object using and the defined parameter grid\n",
    "tree1_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=10, n_jobs=-1)\n",
    "# Fit the GridSearchCV to the balanced training data to find the best hyperparameters\n",
    "tree1_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "# Get the best hyperparameters found by the GridSearch\n",
    "tree1_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92029bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 4, random_state = 1).fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b21e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores\n",
    "importances=tree1.feature_importances_\n",
    "feature_importance_pairs=list(zip(X_train_under.columns, importances))\n",
    "\n",
    "# Sort in descending order\n",
    "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print scores\n",
    "print(\"Feature Importance Scores\")\n",
    "for feature, importance in sorted_feature_importance_pairs:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb82979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19400b7",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fa457",
   "metadata": {},
   "source": [
    "### Random Forest Classifier w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "# Create a Random Forest classifier with 100 trees\n",
    "random_forest = RandomForestClassifier(n_estimators=1000, random_state=1)  \n",
    "\n",
    "# Fit (train) the Random Forest classifier on the balanced training data\n",
    "random_forest.fit(X_train_under, y_train_under.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores\n",
    "importances=random_forest.feature_importances_\n",
    "feature_importance_pairs=list(zip(X_train_under.columns, importances))\n",
    "\n",
    "# Sort in descending order\n",
    "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print scores\n",
    "print(\"Feature Importance Scores\")\n",
    "for feature, importance in sorted_feature_importance_pairs:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6568058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and importances\n",
    "feature_names, importances = zip(*sorted_feature_importance_pairs)\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "#plt.barh(range(len(feature_names)), importances, align='center')\n",
    "#plt.yticks(range(len(feature_names)), feature_names)\n",
    "\n",
    "plt.barh(range(len(feature_names)), importances, align='center')\n",
    "plt.yticks(range(len(feature_names)), feature_names)\n",
    "\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to show the most important features at the top\n",
    "#plt.show()\n",
    "plt.savefig('featimp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b1c42",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77389cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search for in the Gradient Boosting Classifier\n",
    "param_grid = {\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators' : [20,21,22,23,24],\n",
    "}\n",
    "# Create a GridSearchCV object using GradientBoostingClassifier and the defined parameter grid\n",
    "tree_search = GridSearchCV(GradientBoostingClassifier(random_state=1), param_grid, cv=10, n_jobs=-1)\n",
    "# Fit the GridSearchCV to the balanced training data to find the best hyperparameters\n",
    "tree_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "# Get the best hyperparameters found by the GridSearch\n",
    "tree_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b13cc0",
   "metadata": {},
   "source": [
    "## Non-parametric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8fe6c",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41251dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store KNN results\n",
    "knn_results = []\n",
    "for k in range (1, 50):\n",
    "    # Create a K-Nearest Neighbors model with k neighbors and fit it to the balanced training data\n",
    "    knn_mod = KNeighborsClassifier(n_neighbors = k).fit(X_train_under, y_train_under.values.ravel())\n",
    "    # Calculate and append results to the list\n",
    "    knn_results.append({\n",
    "        'k': k,\n",
    "        'Sens': sensitivity_score(y_test_imp.values.ravel(), knn_mod.predict(X_test_combo)),\n",
    "        'Acc': accuracy_score(y_test_imp.values.ravel(), knn_mod.predict(X_test_combo)) \n",
    "    })\n",
    "# Create a DataFrame from the list of KNN results    \n",
    "knn_results = pd.DataFrame(knn_results)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27848ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a K-Nearest Neighbors (KNN) classifier with 6 neighbors and fit it to the balanced training data\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train_under, y_train_under.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3a01c",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0743265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c723211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4aceaf",
   "metadata": {},
   "source": [
    "# Validation Data Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cba06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9f288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9d83de",
   "metadata": {},
   "source": [
    "# Testing Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383afe78",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bfbcc",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8bcb9aba-6cf4-41d0-992c-6278065b2809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product_filgrastim</th>\n",
       "      <th>med_product_iressa</th>\n",
       "      <th>med_product_lenvatinib</th>\n",
       "      <th>med_product_xolair</th>\n",
       "      <th>med_product_xyrem</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>expedited_2</th>\n",
       "      <th>weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.383712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.383712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.041891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    med_product_filgrastim  med_product_iressa  med_product_lenvatinib  \\\n",
       "0                      0.0                 1.0                     0.0   \n",
       "1                      0.0                 1.0                     0.0   \n",
       "2                      1.0                 0.0                     0.0   \n",
       "3                      0.0                 1.0                     0.0   \n",
       "4                      0.0                 0.0                     1.0   \n",
       "5                      0.0                 0.0                     0.0   \n",
       "6                      0.0                 1.0                     0.0   \n",
       "7                      0.0                 0.0                     0.0   \n",
       "8                      0.0                 0.0                     0.0   \n",
       "9                      0.0                 0.0                     1.0   \n",
       "10                     0.0                 0.0                     0.0   \n",
       "11                     0.0                 1.0                     0.0   \n",
       "12                     0.0                 0.0                     0.0   \n",
       "13                     0.0                 0.0                     0.0   \n",
       "14                     0.0                 0.0                     0.0   \n",
       "15                     0.0                 1.0                     0.0   \n",
       "\n",
       "    med_product_xolair  med_product_xyrem  sex_2  expedited_2    weight  year  \n",
       "0                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "1                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "2                  0.0                0.0    1.0          0.0  0.563567   0.0  \n",
       "3                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "4                  0.0                0.0    0.0          1.0 -0.383712   0.0  \n",
       "5                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "6                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "7                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "8                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "9                  0.0                0.0    0.0          1.0 -0.383712   0.0  \n",
       "10                 0.0                1.0    1.0          0.0  1.041891   0.0  \n",
       "11                 0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "12                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "13                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "14                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "15                 0.0                0.0    1.0          0.0 -1.159326   0.0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "04f5bd6b-a49c-49c4-9a5d-2ea1199a2494",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- sex_1\nFeature names seen at fit time, yet now missing:\n- med_product_filgrastim\n- med_product_iressa\n- med_product_lenvatinib\n- med_product_xyrem\n- sex_2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m log_l1\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set (optional but recommended for final evaluation)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlog_l1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_pipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Set Performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- sex_1\nFeature names seen at fit time, yet now missing:\n- med_product_filgrastim\n- med_product_iressa\n- med_product_lenvatinib\n- med_product_xyrem\n- sex_2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a632a6e",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc726260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "log_cm = confusion_matrix(y_true = y_test, y_pred = log_l1.predict(X_test_log), labels = log_l2_bal.classes_)\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix= log_cm_bal, display_labels=log_l2_bal.classes_)\n",
    "log_disp.plot()\n",
    "#plt.show()\n",
    "plt.savefig('lr_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4678622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ced673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for log reg\n",
    "logl1_sens = sensitivity_score(y_test, log_l1.predict(X_test))\n",
    "logl1_spec = specificity_score(y_test, log_l1.predict(X_test))\n",
    "logl1_acc = accuracy_score(y_test, log_l1.predict(X_test))\n",
    "logl1_prec = precision_score(y_test, log_l1.predict(X_test)) \n",
    "logl1_rec = recall_score(y_test, log_l1.predict(X_test))\n",
    "logl1_f1 = f1_score(y_test, log_l1.predict(X_test))\n",
    "logl1_sens, logl1_spec, logl1_acc, logl1_prec, logl1_rec, logl1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6215bd",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823003b",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0c877",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for tree\n",
    "tree_cm = confusion_matrix(y_true = y_test, y_pred = tree1.predict(X_test), labels = tree1.classes_)\n",
    "tree_disp = ConfusionMatrixDisplay(confusion_matrix= tree_cm, display_labels=tree1.classes_)\n",
    "tree_disp.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311da40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for decision tree\n",
    "tree1_sens = sensitivity_score(y_test, tree1.predict(X_test))\n",
    "tree1_spec = specificity_score(y_test, tree1.predict(X_test))\n",
    "tree1_acc = accuracy_score(y_test, tree1.predict(X_test))\n",
    "tree1_prec = precision_score(y_test, tree1.predict(X_test)) \n",
    "tree1_rec = recall_score(y_test, tree1.predict(X_test))\n",
    "tree1_f1 = f1_score(y_test, tree1.predict(X_test))\n",
    "tree1_sens, tree1_spec, tree1_acc, tree1_prec, tree1_rec, tree1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6951a4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d161362",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c35829",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix for RF \n",
    "rf_cm = confusion_matrix(y_true = y_test, y_pred = random_forest.predict(X_test), labels = random_forest.classes_)\n",
    "# Create a ConfusionMatrixDisplay object for visualization\n",
    "rf_disp = ConfusionMatrixDisplay(confusion_matrix= rf_cm, display_labels=random_forest.classes_)\n",
    "rf_disp.plot()\n",
    "warnings.filterwarnings('ignore')\n",
    "#plt.show()\n",
    "#plt.savefig('rf_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b073618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d77c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49636336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for RF\n",
    "rf_sens = sensitivity_score(y_test, random_forest.predict(X_test))\n",
    "rf_spec = specificity_score(y_test, random_forest.predict(X_test))\n",
    "rf_acc = accuracy_score(y_test, random_forest.predict(X_test))\n",
    "rf_prec = precision_score(y_test, random_forest.predict(X_test)) \n",
    "rf_rec = recall_score(y_test, random_forest.predict(X_test))\n",
    "rf_f1 = f1_score(y_test, random_forest.predict(X_test))\n",
    "warnings.filterwarnings('ignore')\n",
    "rf_sens, rf_spec, rf_acc, rf_prec, rf_rec, rf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2109a84",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352e750",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93411af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5bc0b8",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for tree\n",
    "tree_cm = confusion_matrix(y_true = y_test, y_pred = tree_search.predict(X_test), labels = tree_search.classes_)\n",
    "tree_disp = ConfusionMatrixDisplay(confusion_matrix= tree_cm, display_labels=tree_search.classes_)\n",
    "tree_disp.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb565c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for decision tree \n",
    "tree_sens = sensitivity_score(y_test, tree_search.predict(X_test))\n",
    "tree_spec = specificity_score(y_test, tree_search.predict(X_test))\n",
    "tree_acc = accuracy_score(y_test, tree_search.predict(X_test))\n",
    "tree_prec = precision_score(y_test, tree_search.predict(X_test)) \n",
    "tree_rec = recall_score(y_test, tree_search.predict(X_test))\n",
    "tree_f1 = f1_score(y_test, tree_search.predict(X_test))\n",
    "tree_sens, tree_spec, tree_acc, tree_prec, tree_rec, tree_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392f0ac",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16ecfd",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d10f2d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "# Compute the confusion matrix for KNN \n",
    "knn_cm = confusion_matrix(y_true = y_test, y_pred = knn.predict(X_test), labels = knn.classes_)\n",
    "# Create a ConfusionMatrixDisplay object for visualization\n",
    "knn_disp = ConfusionMatrixDisplay(confusion_matrix= knn_cm, display_labels=knn.classes_)\n",
    "knn_disp.plot()\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da866fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for KNN \n",
    "knn_sens = sensitivity_score(y_test, knn.predict(X_test))\n",
    "knn_spec = specificity_score(y_test, knn.predict(X_test))\n",
    "knn_acc = accuracy_score(y_test, knn.predict(X_test))\n",
    "knn_prec = precision_score(y_test, knn.predict(X_test)) \n",
    "knn_rec = recall_score(y_test, knn.predict(X_test))\n",
    "knn_f1 = f1_score(y_test, knn.predict(X_test))\n",
    "warnings.filterwarnings('ignore')\n",
    "knn_sens, knn_spec, knn_acc, knn_prec, knn_rec, knn_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d02998",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca31d3",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9dadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "394a9db7",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e910df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf66096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6290d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48969e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a35ac01",
   "metadata": {},
   "source": [
    "# Performance Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b275bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to display performance metrics for different models on the validation dataset\n",
    "\n",
    "val_performance = [\n",
    "{'Model': 'Neural Net', 'Test Sensitivity': nn_sens, 'Test Specificity':nn_spec, \n",
    " 'Accuracy': nn_acc, 'Test Precision': nn_prec, 'Test Recall': nn_rec, 'F1 Score': nn_f1},\n",
    "    {'Model': 'Logistic Regression', 'Test Sensitivity': logl1_sens, 'Test Specificity':logl1_spec, \n",
    " 'Accuracy': logl1_acc, 'Test Precision': logl1_prec, 'Test Recall': logl1_rec,  'F1 Score': logl1_f1},\n",
    "    {'Model': 'Boosted Tree', 'Test Sensitivity': tree_sens, 'Test Specificity':tree_spec, \n",
    " 'Accuracy': tree_acc, 'Test Precision': tree_prec, 'Test Recall': tree_rec,  'F1 Score': tree_f1},\n",
    "    {'Model': 'Single Tree', 'Test Sensitivity': tree1_sens, 'Test Specificity':tree1_spec, \n",
    " 'Accuracy': tree1_acc, 'Test Precision': tree1_prec, 'Test Recall': tree1_rec, 'F1 Score': tree1_f1},\n",
    "    {'Model': 'Random Forest', 'Test Sensitivity': rf_sens, 'Test Specificity':rf_spec, \n",
    " 'Accuracy': rf_acc, 'Test Precision': rf_prec, 'Test Recall': rf_rec, 'F1 Score': rf_f1},\n",
    "    {'Model': 'K-Nearest Neighbors', 'Test Sensitivity': knn_sens, 'Test Specificity':knn_spec, \n",
    " 'Accuracy': knn_acc, 'Test Precision': knn_prec, 'Test Recall': knn_rec,  'F1 Score': knn_f1},\n",
    "    \n",
    "]\n",
    "# Create a formatted table using tabulate and specify the format as 'fancy_grid'\n",
    "table = tabulate(val_performance, headers='keys', tablefmt='fancy_grid')\n",
    "# Display the comparison table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3d311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302409a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
