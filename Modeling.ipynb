{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26d1edf",
   "metadata": {},
   "source": [
    "# Load Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b84b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "# System, Data, Time, and Spec Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np \n",
    "from line_profiler import LineProfiler  # Code peformance\n",
    "profiler = LineProfiler()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import csv\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "import multiprocess as mp\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "#from pandas.io.json import json_normalize  # Older version\n",
    "from pandas import json_normalize  # Newer version\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "\n",
    "# Natural Language Processing Libraries\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "import string\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas import json_normalize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "punctuation = set(punctuation)\n",
    "punctuation.update({'_', '-','â€˜'})\n",
    "english_words = set(words.words())\n",
    "from fuzzywuzzy import process\n",
    "#nltk.download('words')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# SQL Interface Libraries\n",
    "import pymysql as mysql\n",
    "import mysql.connector\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import event\n",
    "from string import punctuation\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import yeojohnson\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay,roc_auc_score, roc_curve \n",
    "from sklearn.metrics import classification_report, mean_squared_error, f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from dmba import classificationSummary, AIC_score, BIC_score, plotDecisionTree,gainsChart\n",
    "from scikitplot.metrics import plot_lift_curve, plot_cumulative_gain\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.metrics import specificity_score, sensitivity_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import KFold\n",
    "from dmba import stepwise_selection, classificationSummary, backward_elimination\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Importing Custom Functions\n",
    "import nbimporter\n",
    "from Functions import nan_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45efe7",
   "metadata": {},
   "source": [
    "# Test Join Outside of Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05b30919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('DataLibrary/events_table2023.csv')\n",
    "# df2 = pd.read_csv('DataLibrary/patient_drugs_table2023.csv')\n",
    "# df3 = pd.read_csv('DataLibrary/reactions_table2023.csv')\n",
    "\n",
    "# # Merge df1 and df2\n",
    "# merged_df1_df2 = pd.merge(df1, df2, on='event_id', how='inner')\n",
    "\n",
    "# # Merge the result with df3\n",
    "# final_merged_df = pd.merge(merged_df1_df2, df3, on='event_id', how='inner')\n",
    "\n",
    "# # Display the final merged DataFrame\n",
    "# print(final_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f16362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133423, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df1_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b14aff2b-fd02-4373-8f0c-b886ab7e9395",
   "metadata": {},
   "source": [
    "### SQL Password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95daa5f5-c8e9-450b-a74f-b9ade632cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSWORD  = 'PASSWORD' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1ab8a-ee41-484e-ab5f-b37f23b7080f",
   "metadata": {},
   "source": [
    "## Investigate number of records in each database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27b7a789-1b65-4887-8bb7-23dcbdfd0a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0    112551"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql_query = \"\"\"SELECT COUNT(*) FROM patient_reactions\"\"\"\n",
    "\n",
    "\n",
    "cursor.execute(sql_query)\n",
    "result = cursor.fetchall()\n",
    "column_names = [i[0] for i in cursor.description]\n",
    "\n",
    "\n",
    "result_query_df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "result_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f85a2",
   "metadata": {},
   "source": [
    "# Get Dataset from SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cfd9e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MySQL server\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c46ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Master Query from Data - goal\n",
    "\n",
    "# master_query = \"\"\"SELECT \n",
    "#                 a.serious_outcome,\n",
    "#                 a.expedited,\n",
    "#                 a.age,\n",
    "#                 a.sex,\n",
    "#                 a.year\n",
    "#                 a.weight\n",
    "#                 r.outcome,\n",
    "#                 p.unit_price,\n",
    "#                 p.generic_brand,\n",
    "#                 l.ingredients,\n",
    "#                 l.rxcui,\n",
    "#                 l.set_id,\n",
    "#                 d.manu_num,\n",
    "#                 d.unii\n",
    "#             FROM adverse_events a \n",
    "#                 INNER JOIN patients_reactions r ON a.event_id = r.event_id \n",
    "#                 INNER JOIN patients_drugs d ON r.event_id = d.event_id \n",
    "#                 INNER JOIN prices p ON d.ndc11 = p.ndc11\n",
    "#                 INNER JOIN lables l ON p.ndc11 = l.ndc11\n",
    "#             ORDER BY a.event_id DESC\"\"\"  # Still need to test and figure out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4c605-fa87-4a0f-ae9b-7e7e9fceb01c",
   "metadata": {},
   "source": [
    "# Read in data from csv OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d4ca7-e5e6-4609-b25c-ec86c9491585",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df = pd.read_csv('DataLibrary/result_query_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd42033-7ef2-42c5-b917-3fbc23089f2c",
   "metadata": {},
   "source": [
    "# option 2- Read in data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47d32654-430f-42a6-ab82-fc1f4de696ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.15399479866028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>manu_num</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['remicade']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cyclosporine']</td>\n",
       "      <td>24685</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['efalizumab']</td>\n",
       "      <td>24685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['remicade']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['cyclosporine']</td>\n",
       "      <td>24685</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['efalizumab']</td>\n",
       "      <td>24685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        med_product  event_id  manu_num  serious_outcome  expedited  age  sex  \\\n",
       "0       ['stelara']     24685         1                2          1   64    1   \n",
       "1       ['stelara']     24685         1                2          1   64    1   \n",
       "2      ['remicade']     24685         1                2          1   64    1   \n",
       "3  ['cyclosporine']     24685        16                2          1   64    1   \n",
       "4    ['efalizumab']     24685         0                2          1   64    1   \n",
       "5       ['stelara']     24685         1                2          1   64    1   \n",
       "6       ['stelara']     24685         1                2          1   64    1   \n",
       "7      ['remicade']     24685         1                2          1   64    1   \n",
       "8  ['cyclosporine']     24685        16                2          1   64    1   \n",
       "9    ['efalizumab']     24685         0                2          1   64    1   \n",
       "\n",
       "   year  weight outcome  \n",
       "0  2024      72   Fatal  \n",
       "1  2024      72   Fatal  \n",
       "2  2024      72   Fatal  \n",
       "3  2024      72   Fatal  \n",
       "4  2024      72   Fatal  \n",
       "5  2024      72   Fatal  \n",
       "6  2024      72   Fatal  \n",
       "7  2024      72   Fatal  \n",
       "8  2024      72   Fatal  \n",
       "9  2024      72   Fatal  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"localhost\", user=\"root\", password=PASSWORD, database=\"pharma_db\"\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql_query = \"\"\"SELECT \n",
    "d.med_product,\n",
    "d.event_id,\n",
    "d.manu_num,\n",
    "a.serious_outcome,\n",
    "a.expedited,\n",
    "a.age,\n",
    "a.sex,\n",
    "a.year,\n",
    "a.weight,\n",
    "r.outcome\n",
    "FROM adverse_events a \n",
    "\n",
    "INNER JOIN patient_reactions r ON a.event_id = r.event_id\n",
    "INNER JOIN patient_drugs d ON a.event_id = d.event_id\n",
    "ORDER BY a.event_id DESC\n",
    "\"\"\"\n",
    "cursor.execute(sql_query)\n",
    "result = cursor.fetchall()\n",
    "column_names = [i[0] for i in cursor.description]\n",
    "result_query_df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(execution_time)\n",
    "\n",
    "result_query_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53568a97-fd7e-431a-a13e-ca728b5c5742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653735, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_query_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69443ce2-9240-4a79-a342-530b39210669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99193, 10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_query_df = result_query_df.drop_duplicates()\n",
    "result_query_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee4e0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_query_df.to_csv('DataLibrary/result_query_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9fc933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_query_df = result_query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb749f",
   "metadata": {},
   "source": [
    "# Preparation for Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bff08906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>manu_num</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['remicade']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cyclosporine']</td>\n",
       "      <td>24685</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['efalizumab']</td>\n",
       "      <td>24685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['lansoprazole']</td>\n",
       "      <td>24684</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>63</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         med_product  event_id  manu_num  serious_outcome  expedited  age  \\\n",
       "0        ['stelara']     24685         1                2          1   64   \n",
       "2       ['remicade']     24685         1                2          1   64   \n",
       "3   ['cyclosporine']     24685        16                2          1   64   \n",
       "4     ['efalizumab']     24685         0                2          1   64   \n",
       "10  ['lansoprazole']     24684        56                2          1   75   \n",
       "\n",
       "    sex  year  weight outcome  \n",
       "0     1  2024      72   Fatal  \n",
       "2     1  2024      72   Fatal  \n",
       "3     1  2024      72   Fatal  \n",
       "4     1  2024      72   Fatal  \n",
       "10    2  2024      63   Fatal  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d92ebb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med_product</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>event_id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manu_num</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>serious_outcome</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expedited</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weight</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>outcome</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       column_name  null_count  null_proportion\n",
       "0      med_product           0              0.0\n",
       "1         event_id           0              0.0\n",
       "2         manu_num           0              0.0\n",
       "3  serious_outcome           0              0.0\n",
       "4        expedited           0              0.0\n",
       "5              age           0              0.0\n",
       "6              sex           0              0.0\n",
       "7             year           0              0.0\n",
       "8           weight           0              0.0\n",
       "9          outcome           0              0.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_info(master_query_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1a292",
   "metadata": {},
   "source": [
    "### Update Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b15b7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99193 entries, 0 to 2653734\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   med_product      99193 non-null  object\n",
      " 1   event_id         99193 non-null  int64 \n",
      " 2   manu_num         99193 non-null  int64 \n",
      " 3   serious_outcome  99193 non-null  int64 \n",
      " 4   expedited        99193 non-null  int64 \n",
      " 5   age              99193 non-null  int64 \n",
      " 6   sex              99193 non-null  int64 \n",
      " 7   year             99193 non-null  int64 \n",
      " 8   weight           99193 non-null  int64 \n",
      " 9   outcome          99193 non-null  object\n",
      "dtypes: int64(8), object(2)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "master_query_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba278f65",
   "metadata": {},
   "source": [
    "### Define numerical, text, and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12d2e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can do without med_product for now to keep simple, will finish after module 5 submission\n",
    "cats = ['med_product', 'sex', 'expedited']\n",
    "nums = ['weight', 'age', 'manu_num'] \n",
    "#texts = ['']  # Do reaction and med product as text vector instead of binary matrix? only test out if time permits\n",
    "#all_vars = cats+nums+texts\"\n",
    "all_vars = cats+nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2aa3854-cdd8-4ed9-a7e2-a9367d7d0adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>event_id</th>\n",
       "      <th>manu_num</th>\n",
       "      <th>serious_outcome</th>\n",
       "      <th>expedited</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "      <th>weight</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['stelara']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['remicade']</td>\n",
       "      <td>24685</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cyclosporine']</td>\n",
       "      <td>24685</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['efalizumab']</td>\n",
       "      <td>24685</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>72</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['lansoprazole']</td>\n",
       "      <td>24684</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>63</td>\n",
       "      <td>Fatal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         med_product  event_id  manu_num  serious_outcome  expedited  age  \\\n",
       "0        ['stelara']     24685         1                2          1   64   \n",
       "2       ['remicade']     24685         1                2          1   64   \n",
       "3   ['cyclosporine']     24685        16                2          1   64   \n",
       "4     ['efalizumab']     24685         0                2          1   64   \n",
       "10  ['lansoprazole']     24684        56                2          1   75   \n",
       "\n",
       "    sex  year  weight outcome  \n",
       "0     1  2024      72   Fatal  \n",
       "2     1  2024      72   Fatal  \n",
       "3     1  2024      72   Fatal  \n",
       "4     1  2024      72   Fatal  \n",
       "10    2  2024      63   Fatal  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e604641-49f8-4658-b0d8-ce35f4e9f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['med_product', 'event_id', 'manu_num', 'serious_outcome', 'expedited',\n",
       "       'age', 'sex', 'year', 'weight', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_query_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "095d71fb-09d8-4137-9090-c2dc3d798921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['med_product', 'sex', 'expedited', 'weight', 'age', 'manu_num']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd9a25",
   "metadata": {},
   "source": [
    "### Create Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96e0fd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(transformers=[('cat',\n",
       "                                  Pipeline(steps=[('encoder',\n",
       "                                                   OneHotEncoder(drop='if_binary'))]),\n",
       "                                  ['med_product', 'sex', 'expedited']),\n",
       "                                 ('num',\n",
       "                                  Pipeline(steps=[('skew_standardize',\n",
       "                                                   PowerTransformer())]),\n",
       "                                  ['weight', 'age', 'manu_num'])],\n",
       "                   verbose_feature_names_out=False)}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = ['med_product', 'sex', 'expedited']\n",
    "nums = ['weight', 'age', 'manu_num'] \n",
    "\n",
    "# Create a categorical processing pipeline that uses one-hot encoding\n",
    "# Dropping binary columns and drop first of each level** NEED TO ADD**\n",
    "cat_pipe = Pipeline([('encoder', OneHotEncoder(drop='if_binary'))])\n",
    "\n",
    "# Create a numerical processing pipeline that uses skewness correction/center/scale.\n",
    "num_pipe = Pipeline([('skew_standardize', PowerTransformer())])\n",
    "\n",
    "# Create a text token processing step to vectorize tokens\n",
    "#text_pipe = Pipeline([('vector', tf_idf function())])\n",
    "\n",
    "# Combine pipeline steps\n",
    "all_pipe = make_pipeline(\n",
    "    ColumnTransformer([\n",
    "        ('cat', cat_pipe, cats),  # Apply categorical pipeline to categorical columns\n",
    "        ('num', num_pipe, nums),  # Apply numerical pipeline to numerical columns\n",
    "     #   ('text', text_pipe, texts)  # Apply text pipeline to text columns\n",
    "    ],\n",
    "    verbose_feature_names_out=False)  # Set this to False to avoid verbose feature names\n",
    ")\n",
    "# Verify steps\n",
    "\n",
    "all_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b208e",
   "metadata": {},
   "source": [
    "# Split Data into Training/Validation/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "23f9eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and the target variable (y).\n",
    "X = master_query_df[all_vars]\n",
    "\n",
    "#Define outcome variable\n",
    "y = master_query_df[['serious_outcome']]  # Need to Decide 5 Level or 3 Level\n",
    "\n",
    "#Split data\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, train_size=0.8, random_state = 2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b64b6b65-0802-43cd-ae63-caf0aedaa12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>sex</th>\n",
       "      <th>expedited</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>manu_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1617080</th>\n",
       "      <td>['rituximab']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437331</th>\n",
       "      <td>['methotrexate']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432915</th>\n",
       "      <td>['metoclopramide']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521465</th>\n",
       "      <td>['viread']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255957</th>\n",
       "      <td>['lovenox']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                med_product  sex  expedited  weight  age  manu_num\n",
       "1617080       ['rituximab']    1          1      78   71         1\n",
       "2437331    ['methotrexate']    2          1      68   43        21\n",
       "432915   ['metoclopramide']    2          1      89   69         9\n",
       "2521465          ['viread']    1          1      60   48         1\n",
       "1255957         ['lovenox']    2          1      63   70         1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1788f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79354, 6), (79354, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5c8c79e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9920, 6), (9920, 1))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "391dca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9919, 6), (9919, 1))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46fad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e15bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "032c0f4a",
   "metadata": {},
   "source": [
    "## Apply Pipeline to Splits Separately to Prevent Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8b61f3c-0269-4f69-b101-64be3bda1c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product</th>\n",
       "      <th>sex</th>\n",
       "      <th>expedited</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>manu_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>684183</th>\n",
       "      <td>['carboplatin']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34813</th>\n",
       "      <td>['gadobutrol']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440773</th>\n",
       "      <td>['januvia']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619947</th>\n",
       "      <td>['prolia']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406429</th>\n",
       "      <td>['ocrevus']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             med_product  sex  expedited  weight  age  manu_num\n",
       "684183   ['carboplatin']    2          1      71   52        11\n",
       "34813     ['gadobutrol']    2          1      59   16         3\n",
       "440773       ['januvia']    1          1      42   77         1\n",
       "2619947       ['prolia']    1          1      81   75         1\n",
       "406429       ['ocrevus']    1          1      95   71         1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "854b7a90-237b-4f9a-aaf6-54f6e732293b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['med_product', 'sex', 'expedited', 'weight', 'age', 'manu_num'], dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c3e87-8cd2-4f24-95fc-fc8611070985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b33ffad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "get_feature_names_out not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m X_train_fit \u001b[38;5;241m=\u001b[39m all_pipe\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Get feature names out from fit and create as new list\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train_cols \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#X_train_pipe = pd.DataFrame(all_pipe.fit_transform(X_train), columns = X_train_cols)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py:687\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetnnz()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: get_feature_names_out not found"
     ]
    }
   ],
   "source": [
    "\n",
    "#Apply pipeline to all of X\n",
    "X_train_fit = all_pipe.fit_transform(X_train)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_train_cols = X_train_fit.get_feature_names_out().tolist()\n",
    "#X_train_pipe = pd.DataFrame(all_pipe.fit_transform(X_train), columns = X_train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68d1702f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'med_product'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:448\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 448\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'med_product'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Apply pipeline to all of X\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_test_fit \u001b[38;5;241m=\u001b[39m \u001b[43mall_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Get feature names out from fit and create as new list\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X_test_cols \u001b[38;5;241m=\u001b[39m X_test_fit\u001b[38;5;241m.\u001b[39mget_feature_names_out()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:694\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    This estimator.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 724\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    727\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    424\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    425\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:456\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    453\u001b[0m             column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "#Apply pipeline to all of X\n",
    "X_test_fit = all_pipe.fit(X_test)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_test_cols = X_test_fit.get_feature_names_out().tolist()\n",
    "X_test_pipe = pd.DataFrame(all_pipe.fit_transform(X_test), columns = X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "954529f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'med_product'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:448\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 448\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'med_product'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Apply pipeline to all of X\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_val_fit \u001b[38;5;241m=\u001b[39m \u001b[43mall_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Get feature names out from fit and create as new list\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X_val_cols \u001b[38;5;241m=\u001b[39m X_val_fit\u001b[38;5;241m.\u001b[39mget_feature_names_out()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:694\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    This estimator.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 724\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    727\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    424\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    425\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/__init__.py:456\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    453\u001b[0m             column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "#Apply pipeline to all of X\n",
    "X_val_fit = all_pipe.fit(X_val)\n",
    "#Get feature names out from fit and create as new list\n",
    "X_val_cols = X_val_fit.get_feature_names_out().tolist()\n",
    "X_val_pipe = pd.DataFrame(all_pipe.fit_transform(X_val), columns = X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb650195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e207ea03",
   "metadata": {},
   "source": [
    "## Undersample Training Data to Balance Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0a5fdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomUnderSampler instance with a specified random seed and sampling strategy\n",
    "rus = RandomUnderSampler(random_state = 1, sampling_strategy='majority')\n",
    "\n",
    "# Perform random under-sampling on the training dataset\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_pipe, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ba158",
   "metadata": {},
   "source": [
    "# Multiclass Classification Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed355f",
   "metadata": {},
   "source": [
    "## White Box Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cb1cc-ad2c-41d9-8f9e-c617aabd3bc5",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec591d-8f63-4b01-8e85-9cec598ee4a0",
   "metadata": {},
   "source": [
    "### Logistic Regression L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7646a70b-9aca-40a1-8b0a-f23cabc53c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "med_product_filgrastim    float64\n",
       "med_product_iressa        float64\n",
       "med_product_lenvatinib    float64\n",
       "med_product_xolair        float64\n",
       "med_product_xyrem         float64\n",
       "sex_2                     float64\n",
       "expedited_2               float64\n",
       "weight                    float64\n",
       "year                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5213ceeb-15d8-4c8f-8436-ad51feb0c294",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"['carboplatin']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9n/rvh416ss641f86jq46p9wy380000gn/T/ipykernel_1399/2381912928.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlog_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Intercept Log-Odds and Odds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1197\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         raise ValueError(\n\u001b[1;32m   1103\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    882\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m                 ) from complex_warning\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"['carboplatin']\""
     ]
    }
   ],
   "source": [
    "log_l1 = LogisticRegression(solver='saga', penalty='l1', random_state=1)\n",
    "log_l1.fit(X_train, y_train)\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l1.intercept_ , np.exp(log_l1.intercept_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec3450-150c-4d8a-95a4-90553e38c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca165463-02fb-4ea6-a213-2cca1db37508",
   "metadata": {},
   "source": [
    "### Logistic Regression L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5878cf4e-6867-4944-bfab-fdcca9725168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12139508] [0.88568397]\n"
     ]
    }
   ],
   "source": [
    "log_l2 = LogisticRegression(solver='saga', penalty='l2', random_state=1)\n",
    "log_l2.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l2.intercept_ , np.exp(log_l2.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1a1d5",
   "metadata": {},
   "source": [
    "### Logistic Regression L1 w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "207a804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03186184] [1.03237486]\n"
     ]
    }
   ],
   "source": [
    "# Create Logistic Regression model with L1 regularization\n",
    "log_l1_cv = LogisticRegressionCV(solver = 'saga', penalty = 'l1', cv = 2, random_state = 1)\n",
    "# Fit the model to the training data\n",
    "log_l1_cv.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "# Intercept Log-Odds and Odds\n",
    "print(log_l1_cv.intercept_ , np.exp(log_l1_cv.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63857388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "becf7b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>LogOdds</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weight</td>\n",
       "      <td>-1.492369</td>\n",
       "      <td>0.224839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med_product_filgrastim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med_product_iressa</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>med_product_lenvatinib</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>med_product_xolair</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>med_product_xyrem</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sex_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expedited_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature   LogOdds      Odds\n",
       "7                  weight -1.492369  0.224839\n",
       "0  med_product_filgrastim  0.000000  1.000000\n",
       "1      med_product_iressa  0.000000  1.000000\n",
       "2  med_product_lenvatinib  0.000000  1.000000\n",
       "3      med_product_xolair  0.000000  1.000000\n",
       "4       med_product_xyrem  0.000000  1.000000\n",
       "5                   sex_2  0.000000  1.000000\n",
       "6             expedited_2  0.000000  1.000000\n",
       "8                    year  0.000000  1.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table of coefficient odds\n",
    "d = {'Feature': pd.Series(X_train_under.columns), 'LogOdds': pd.Series(log_l1_cv.coef_[0])}\n",
    "df = pd.DataFrame(data=d).reindex(d['LogOdds'].abs().sort_values(ascending=False).index)\n",
    "df['Odds'] = np.exp(df['LogOdds'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ed9e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ecbaa-f992-4535-a36f-0153dfe8a5a2",
   "metadata": {},
   "source": [
    "### Logistic Regression Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7ad0abb-4c8f-4d9c-8ba4-b590dbb94fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'l1_ratio': 0.0}\n",
      "Best cross-validation score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'l1_ratio': [i / 9 for i in range(10)],  # 10 values from 0 to 1 (0, 0.1, 0.2, ..., 1.0)\n",
    "    'C': [0.01, 0.1, 1, 10, 100]  # Different strengths of regularization\n",
    "}\n",
    "\n",
    "log_reg_elasticnet = LogisticRegression(\n",
    "    penalty='elasticnet',  # Use Elastic Net regularization\n",
    "    solver='saga',        # Solver that supports Elastic Net\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg_elasticnet,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',   # Or another metric of choice\n",
    "    cv=5,                 # Number of cross-validation folds\n",
    "    n_jobs=-1              # Use all available CPUs\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best cross-validation score: {best_score:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e3159",
   "metadata": {},
   "source": [
    "### SINGLE DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adfed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search for in tree\n",
    "param_grid = {\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'min_samples_leaf' : [1,2,3,4,5]\n",
    "    \n",
    "}\n",
    "# Create a GridSearchCV object using and the defined parameter grid\n",
    "tree1_search = GridSearchCV(DecisionTreeClassifier(random_state=1), param_grid, cv=10, n_jobs=-1)\n",
    "# Fit the GridSearchCV to the balanced training data to find the best hyperparameters\n",
    "tree1_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "# Get the best hyperparameters found by the GridSearch\n",
    "tree1_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92029bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 4, random_state = 1).fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b21e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores\n",
    "importances=tree1.feature_importances_\n",
    "feature_importance_pairs=list(zip(X_train_under.columns, importances))\n",
    "\n",
    "# Sort in descending order\n",
    "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print scores\n",
    "print(\"Feature Importance Scores\")\n",
    "for feature, importance in sorted_feature_importance_pairs:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb82979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19400b7",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fa457",
   "metadata": {},
   "source": [
    "### Random Forest Classifier w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "# Create a Random Forest classifier with 100 trees\n",
    "random_forest = RandomForestClassifier(n_estimators=1000, random_state=1)  \n",
    "\n",
    "# Fit (train) the Random Forest classifier on the balanced training data\n",
    "random_forest.fit(X_train_under, y_train_under.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores\n",
    "importances=random_forest.feature_importances_\n",
    "feature_importance_pairs=list(zip(X_train_under.columns, importances))\n",
    "\n",
    "# Sort in descending order\n",
    "sorted_feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print scores\n",
    "print(\"Feature Importance Scores\")\n",
    "for feature, importance in sorted_feature_importance_pairs:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6568058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and importances\n",
    "feature_names, importances = zip(*sorted_feature_importance_pairs)\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(14, 12))\n",
    "#plt.barh(range(len(feature_names)), importances, align='center')\n",
    "#plt.yticks(range(len(feature_names)), feature_names)\n",
    "\n",
    "plt.barh(range(len(feature_names)), importances, align='center')\n",
    "plt.yticks(range(len(feature_names)), feature_names)\n",
    "\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to show the most important features at the top\n",
    "#plt.show()\n",
    "plt.savefig('featimp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b1c42",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree w/ 10-k CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77389cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to search for in the Gradient Boosting Classifier\n",
    "param_grid = {\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'n_estimators' : [20,21,22,23,24],\n",
    "}\n",
    "# Create a GridSearchCV object using GradientBoostingClassifier and the defined parameter grid\n",
    "tree_search = GridSearchCV(GradientBoostingClassifier(random_state=1), param_grid, cv=10, n_jobs=-1)\n",
    "# Fit the GridSearchCV to the balanced training data to find the best hyperparameters\n",
    "tree_search.fit(X_train_under, y_train_under.values.ravel())\n",
    "# Get the best hyperparameters found by the GridSearch\n",
    "tree_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross val performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b13cc0",
   "metadata": {},
   "source": [
    "## Non-parametric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8fe6c",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41251dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store KNN results\n",
    "knn_results = []\n",
    "for k in range (1, 50):\n",
    "    # Create a K-Nearest Neighbors model with k neighbors and fit it to the balanced training data\n",
    "    knn_mod = KNeighborsClassifier(n_neighbors = k).fit(X_train_under, y_train_under.values.ravel())\n",
    "    # Calculate and append results to the list\n",
    "    knn_results.append({\n",
    "        'k': k,\n",
    "        'Sens': sensitivity_score(y_test_imp.values.ravel(), knn_mod.predict(X_test_combo)),\n",
    "        'Acc': accuracy_score(y_test_imp.values.ravel(), knn_mod.predict(X_test_combo)) \n",
    "    })\n",
    "# Create a DataFrame from the list of KNN results    \n",
    "knn_results = pd.DataFrame(knn_results)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27848ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a K-Nearest Neighbors (KNN) classifier with 6 neighbors and fit it to the balanced training data\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train_under, y_train_under.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3a01c",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0743265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c723211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4aceaf",
   "metadata": {},
   "source": [
    "# Validation Data Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cba06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9f288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9d83de",
   "metadata": {},
   "source": [
    "# Testing Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383afe78",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bfbcc",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8bcb9aba-6cf4-41d0-992c-6278065b2809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_product_filgrastim</th>\n",
       "      <th>med_product_iressa</th>\n",
       "      <th>med_product_lenvatinib</th>\n",
       "      <th>med_product_xolair</th>\n",
       "      <th>med_product_xyrem</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>expedited_2</th>\n",
       "      <th>weight</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.383712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.383712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.041891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.159326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    med_product_filgrastim  med_product_iressa  med_product_lenvatinib  \\\n",
       "0                      0.0                 1.0                     0.0   \n",
       "1                      0.0                 1.0                     0.0   \n",
       "2                      1.0                 0.0                     0.0   \n",
       "3                      0.0                 1.0                     0.0   \n",
       "4                      0.0                 0.0                     1.0   \n",
       "5                      0.0                 0.0                     0.0   \n",
       "6                      0.0                 1.0                     0.0   \n",
       "7                      0.0                 0.0                     0.0   \n",
       "8                      0.0                 0.0                     0.0   \n",
       "9                      0.0                 0.0                     1.0   \n",
       "10                     0.0                 0.0                     0.0   \n",
       "11                     0.0                 1.0                     0.0   \n",
       "12                     0.0                 0.0                     0.0   \n",
       "13                     0.0                 0.0                     0.0   \n",
       "14                     0.0                 0.0                     0.0   \n",
       "15                     0.0                 1.0                     0.0   \n",
       "\n",
       "    med_product_xolair  med_product_xyrem  sex_2  expedited_2    weight  year  \n",
       "0                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "1                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "2                  0.0                0.0    1.0          0.0  0.563567   0.0  \n",
       "3                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "4                  0.0                0.0    0.0          1.0 -0.383712   0.0  \n",
       "5                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "6                  0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "7                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "8                  1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "9                  0.0                0.0    0.0          1.0 -0.383712   0.0  \n",
       "10                 0.0                1.0    1.0          0.0  1.041891   0.0  \n",
       "11                 0.0                0.0    1.0          0.0 -1.159326   0.0  \n",
       "12                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "13                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "14                 1.0                0.0    0.0          0.0  1.019654   0.0  \n",
       "15                 0.0                0.0    1.0          0.0 -1.159326   0.0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "04f5bd6b-a49c-49c4-9a5d-2ea1199a2494",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- sex_1\nFeature names seen at fit time, yet now missing:\n- med_product_filgrastim\n- med_product_iressa\n- med_product_lenvatinib\n- med_product_xyrem\n- sex_2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m log_l1\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set (optional but recommended for final evaluation)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlog_l1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_pipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Set Performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- sex_1\nFeature names seen at fit time, yet now missing:\n- med_product_filgrastim\n- med_product_iressa\n- med_product_lenvatinib\n- med_product_xyrem\n- sex_2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a632a6e",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc726260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "log_cm = confusion_matrix(y_true = y_test, y_pred = log_l1.predict(X_test_log), labels = log_l2_bal.classes_)\n",
    "log_disp = ConfusionMatrixDisplay(confusion_matrix= log_cm_bal, display_labels=log_l2_bal.classes_)\n",
    "log_disp.plot()\n",
    "#plt.show()\n",
    "plt.savefig('lr_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4678622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ced673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for log reg\n",
    "logl1_sens = sensitivity_score(y_test, log_l1.predict(X_test))\n",
    "logl1_spec = specificity_score(y_test, log_l1.predict(X_test))\n",
    "logl1_acc = accuracy_score(y_test, log_l1.predict(X_test))\n",
    "logl1_prec = precision_score(y_test, log_l1.predict(X_test)) \n",
    "logl1_rec = recall_score(y_test, log_l1.predict(X_test))\n",
    "logl1_f1 = f1_score(y_test, log_l1.predict(X_test))\n",
    "logl1_sens, logl1_spec, logl1_acc, logl1_prec, logl1_rec, logl1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6215bd",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823003b",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0c877",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for tree\n",
    "tree_cm = confusion_matrix(y_true = y_test, y_pred = tree1.predict(X_test), labels = tree1.classes_)\n",
    "tree_disp = ConfusionMatrixDisplay(confusion_matrix= tree_cm, display_labels=tree1.classes_)\n",
    "tree_disp.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311da40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for decision tree\n",
    "tree1_sens = sensitivity_score(y_test, tree1.predict(X_test))\n",
    "tree1_spec = specificity_score(y_test, tree1.predict(X_test))\n",
    "tree1_acc = accuracy_score(y_test, tree1.predict(X_test))\n",
    "tree1_prec = precision_score(y_test, tree1.predict(X_test)) \n",
    "tree1_rec = recall_score(y_test, tree1.predict(X_test))\n",
    "tree1_f1 = f1_score(y_test, tree1.predict(X_test))\n",
    "tree1_sens, tree1_spec, tree1_acc, tree1_prec, tree1_rec, tree1_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6951a4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d161362",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c35829",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix for RF \n",
    "rf_cm = confusion_matrix(y_true = y_test, y_pred = random_forest.predict(X_test), labels = random_forest.classes_)\n",
    "# Create a ConfusionMatrixDisplay object for visualization\n",
    "rf_disp = ConfusionMatrixDisplay(confusion_matrix= rf_cm, display_labels=random_forest.classes_)\n",
    "rf_disp.plot()\n",
    "warnings.filterwarnings('ignore')\n",
    "#plt.show()\n",
    "#plt.savefig('rf_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b073618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d77c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49636336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for RF\n",
    "rf_sens = sensitivity_score(y_test, random_forest.predict(X_test))\n",
    "rf_spec = specificity_score(y_test, random_forest.predict(X_test))\n",
    "rf_acc = accuracy_score(y_test, random_forest.predict(X_test))\n",
    "rf_prec = precision_score(y_test, random_forest.predict(X_test)) \n",
    "rf_rec = recall_score(y_test, random_forest.predict(X_test))\n",
    "rf_f1 = f1_score(y_test, random_forest.predict(X_test))\n",
    "warnings.filterwarnings('ignore')\n",
    "rf_sens, rf_spec, rf_acc, rf_prec, rf_rec, rf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2109a84",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352e750",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93411af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5bc0b8",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for tree\n",
    "tree_cm = confusion_matrix(y_true = y_test, y_pred = tree_search.predict(X_test), labels = tree_search.classes_)\n",
    "tree_disp = ConfusionMatrixDisplay(confusion_matrix= tree_cm, display_labels=tree_search.classes_)\n",
    "tree_disp.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb565c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for decision tree \n",
    "tree_sens = sensitivity_score(y_test, tree_search.predict(X_test))\n",
    "tree_spec = specificity_score(y_test, tree_search.predict(X_test))\n",
    "tree_acc = accuracy_score(y_test, tree_search.predict(X_test))\n",
    "tree_prec = precision_score(y_test, tree_search.predict(X_test)) \n",
    "tree_rec = recall_score(y_test, tree_search.predict(X_test))\n",
    "tree_f1 = f1_score(y_test, tree_search.predict(X_test))\n",
    "tree_sens, tree_spec, tree_acc, tree_prec, tree_rec, tree_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392f0ac",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16ecfd",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d10f2d",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "# Compute the confusion matrix for KNN \n",
    "knn_cm = confusion_matrix(y_true = y_test, y_pred = knn.predict(X_test), labels = knn.classes_)\n",
    "# Create a ConfusionMatrixDisplay object for visualization\n",
    "knn_disp = ConfusionMatrixDisplay(confusion_matrix= knn_cm, display_labels=knn.classes_)\n",
    "knn_disp.plot()\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da866fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity, specificity, and accuracy for KNN \n",
    "knn_sens = sensitivity_score(y_test, knn.predict(X_test))\n",
    "knn_spec = specificity_score(y_test, knn.predict(X_test))\n",
    "knn_acc = accuracy_score(y_test, knn.predict(X_test))\n",
    "knn_prec = precision_score(y_test, knn.predict(X_test)) \n",
    "knn_rec = recall_score(y_test, knn.predict(X_test))\n",
    "knn_f1 = f1_score(y_test, knn.predict(X_test))\n",
    "warnings.filterwarnings('ignore')\n",
    "knn_sens, knn_spec, knn_acc, knn_prec, knn_rec, knn_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d02998",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca31d3",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9dadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "394a9db7",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e910df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf66096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6290d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48969e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a35ac01",
   "metadata": {},
   "source": [
    "# Performance Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b275bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table to display performance metrics for different models on the validation dataset\n",
    "\n",
    "val_performance = [\n",
    "{'Model': 'Neural Net', 'Test Sensitivity': nn_sens, 'Test Specificity':nn_spec, \n",
    " 'Accuracy': nn_acc, 'Test Precision': nn_prec, 'Test Recall': nn_rec, 'F1 Score': nn_f1},\n",
    "    {'Model': 'Logistic Regression', 'Test Sensitivity': logl1_sens, 'Test Specificity':logl1_spec, \n",
    " 'Accuracy': logl1_acc, 'Test Precision': logl1_prec, 'Test Recall': logl1_rec,  'F1 Score': logl1_f1},\n",
    "    {'Model': 'Boosted Tree', 'Test Sensitivity': tree_sens, 'Test Specificity':tree_spec, \n",
    " 'Accuracy': tree_acc, 'Test Precision': tree_prec, 'Test Recall': tree_rec,  'F1 Score': tree_f1},\n",
    "    {'Model': 'Single Tree', 'Test Sensitivity': tree1_sens, 'Test Specificity':tree1_spec, \n",
    " 'Accuracy': tree1_acc, 'Test Precision': tree1_prec, 'Test Recall': tree1_rec, 'F1 Score': tree1_f1},\n",
    "    {'Model': 'Random Forest', 'Test Sensitivity': rf_sens, 'Test Specificity':rf_spec, \n",
    " 'Accuracy': rf_acc, 'Test Precision': rf_prec, 'Test Recall': rf_rec, 'F1 Score': rf_f1},\n",
    "    {'Model': 'K-Nearest Neighbors', 'Test Sensitivity': knn_sens, 'Test Specificity':knn_spec, \n",
    " 'Accuracy': knn_acc, 'Test Precision': knn_prec, 'Test Recall': knn_rec,  'F1 Score': knn_f1},\n",
    "    \n",
    "]\n",
    "# Create a formatted table using tabulate and specify the format as 'fancy_grid'\n",
    "table = tabulate(val_performance, headers='keys', tablefmt='fancy_grid')\n",
    "# Display the comparison table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3d311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302409a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
